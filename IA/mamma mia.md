---
title: Mamma mIA !
layout: default 
nav_order: 1
parent: IA
---

# Mamma mia !

## Les dÃ©buts...

Jâ€™ai commencÃ© Ã  dÃ©velopper assez tÃ´t, en classe de 4áµ‰. Jâ€™avais rÃ©ussi Ã  convaincre mes parents de nous offrir, Ã  mon frÃ©rot Vincent et Ã  moi-mÃªme, un ordinateur. Jâ€™avais dÃ©jÃ  un jeu dâ€™Ã©checs Ã©lectronique avec lequel je jouais des heures. Mon pÃ¨re, pÃ©dagogue et ma mÃ¨re, prof de franÃ§ais, Ã  force dâ€™arguments et dâ€™enquÃªtes auprÃ¨s de leurs collÃ¨gues - surtout profs de mathsğŸ˜‰ -, ont fini par cÃ©der. AprÃ¨s tout, câ€™Ã©tait mis en avant par lâ€™Ã‰ducation nationaleâ€¯â€” il sâ€™agissait du TO7 ğŸ˜„â€¯â€”â€¯les programmes Ã©taient Ã  visÃ©e pÃ©dagogique, un peu ludiques, mais rien Ã  voir avec le cÃ´tÃ© peu crÃ©atif des consoles Atari ou des jeux Ã  cristaux liquides que nos cousins possÃ©daient et qui semblaient du point de vue de nos parents bien abrutissants (pas du mien ğŸ˜‰).

Je me souviens avoir passÃ© des heures Ã  restituer les lignes de code contenues dans des livres ou des revues dâ€™informatique (Hebdogiciel). Et dÃ©jÃ , Ã©crire ces lignes de code que lâ€™ordinateur Ã©tait capable de comprendre et auxquelles il obÃ©issait, câ€™Ã©tait comme un dialogue qui sâ€™opÃ©rait avec une entitÃ© presque vivante, capable de rÃ¢ler â€œSYNTAX ERRORâ€, dâ€™Ã©ructer avec cette voix stridente lors de la lecture des cassettes, de sâ€™Ã©teindre Ã  la moindre coupure de courant, nous faisant perdre les quelques heures passÃ©es Ã  lui donner patiemment des instructions.

Mais je me souviens tout particuliÃ¨rement dâ€™un articleâ€¯; câ€™Ã©tait dans la revue â€œScience & Vieâ€, peut-Ãªtre en 1985 ou 1986, et Ã§a parlait du fameux test de Turing en donnant un exemple basique de comment programmer une sorte de dialogue avec la machine qui puisse â€œblufferâ€ Ã  partir de quelques rÃ©ponses Ã  des questions toutes faites, prÃ©alablement posÃ©es par la machine. (Elle nous posait des questions, retenait les rÃ©ponses puis nous demandait de lâ€™interroger sur ce mÃªme champ de questions.) Pas hyper difficile Ã  coder, mais facile Ã  mettre en dÃ©faut, facile Ã  dÃ©celer la supercherieâ€¦ en tout cas, Ã§a mâ€™avait bien amusÃ© de coder Ã§a en BASIC sur le TO7 qui commenÃ§ait dÃ©jÃ  Ã  montrer de sÃ©rieuses limites.


## Les Ã©tudes ....

Un peu plus tard, lors de mes Ã©tudes, il y a eu la programmation dâ€™un moteur de systÃ¨me expert en projet de maÃ®trise, dâ€™un mini-compilateur Pascal, lâ€™apprentissage du Prolog, du LISP, des algos minimax, la recherche dâ€™optimum, la thÃ©orie des graphes et le fameux problÃ¨me du voyageur de commerce. Concernant les rÃ©seaux de neurones, câ€™Ã©tait un peu plus tard, lors de mon DESS Ã  Lille. Mais Ã§a ne faisait quâ€™effleurer la thÃ©orie (en 1995)â€¯: perceptron, rÃ©seaux multicouches. Un des TPs a consistÃ© Ã  coder une reconnaissance de caractÃ¨re via un rÃ©seau de Hopfieldâ€¦ rigolo, intÃ©ressant, mais trÃ¨s limitÃ©.


## Le boulot ...

Ensuite, dans le cadre du travail, un systÃ¨me de rÃ¨gles pour la validation des rÃ©sultats, sâ€™apparentant, en poussant un peu, Ã  une sorte de systÃ¨me expertâ€¯puis une Ã©tude pour utiliser les algorithmes de machine learning (ml.net) afin d'essayer de valider automatiquement des rÃ©sultats de laboratoire Ã  partir de critÃ¨res (sexe, Ã¢ge, rÃ©sultat du test biologique) en s'affranchissant des bornes de normalitÃ© qu'un laboratoire dÃ©finit en fonction des tests et des populations (enfant, adulte homme, adulte femme et tout les sous ensembles liÃ©s Ã  l'Ã¢ge ). Plus ambitieux, j'ai tentÃ© d'entrainer le model avec des graphes de rÃ©sultats afin de pouvoir les valider automatiquement. 

Câ€™Ã©tait dans le cadre dâ€™un hackathon interne, et câ€™est restÃ© dans les cartons, sacrifiÃ© sur lâ€™autel des prioritÃ©s. Il faut dire que les rÃ©sultats nâ€™Ã©taient pas non plus hyper concluantsâ€¯: les fameuses rÃ¨gles du systÃ¨me expert Ã©taient bien suffisantes pour arriver au mÃªme rÃ©sultat, les types de variables dâ€™entrÃ©e Ã©tant plutÃ´t limitÃ©s. J'avais remarquÃ© d'ailleurs que c'etaient les algorithmes Ã  base dâ€™arbres de dÃ©cision qui avaient fourni le modÃ¨le le plus concluant, les donnÃ©es d'entraÃ®nement ayant Ã©tÃ© labelisÃ©s prÃ©alablement via le systÃ¨me expert qui est, de par sa nature, un arbre de dÃ©cision sur des donnÃ©es non sÃ©parables lineairement.

eg. if sexe= homme and if age <10y then population=Child

Quant Ã  essayer de valider les rÃ©sultats sur la base des graphes, je n'avais pas rÃ©ussi Ã  rassembler suffisamment de graphes d'entraÃ®nement pour obtenir des prÃ©dictions cohÃ©rentes. Et surtout, utiliser la reconnaissance d'image sur des graphes obtenus Ã  partir de quelques points, est-ce vraiment utileâ€¯? Autant travailler directement sur la valeur des points...

Jâ€™Ã©tais donc un peu restÃ© sur ma faim, avec lâ€™idÃ©e de reprendre un jour ce sujet et de trouver un domaine dâ€™application plus pertinent. Câ€™est toujours Ã§a la difficultÃ©â€¯: il y a plein dâ€™exemples qui tournent parfaitement dans les tutos, mais dÃ¨s quâ€™on veut appliquer Ã  nos problÃ©matiques mÃ©tier, Ã§a devient tout de suite beaucoup moins trivial ou moins conluant!

# Cette annÃ©e lÃ ...

Cette annÃ©e-lÃ , pour moi â€” 2025 â€” a Ã©tÃ© celle de la grande intÃ©gration des LLMs suivant deux axes : la mise en place dâ€™outils pour les dÃ©veloppeurs (Github Copilot) avec la mesure du fameux ROI pour faire plaisir aux managers qui ont toujours besoin de chiffres et KPIs pour Ãªtre convaincus. 

- CapacitÃ© Ã  pondre des tests unitaires, Ã  expliquer du code, Ã  gÃ©nÃ©rer de la documentation de design et des diagrammes UML, et surtout, Ã  produire du code et des exemples dâ€™utilisation de frameworks : la productivitÃ© sâ€™en est trouvÃ©e accrue, câ€™est indÃ©niable, mais je reviendrai sur les risques encourus pour notre savoir-faire et notre mÃ©tier dans d'autres reflexions.

- Plus intÃ©ressant, le second axe a consistÃ© Ã  mettre en place un chatbot maison. On voulait que le chatbot puisse utiliser toutes nos documentations pour aider les ingÃ©nieurs terrains Ã  configurer, trouver des rÃ©ponses Ã  des problÃ¨mes connus, une sorte de support niveau 1.
On sâ€™est posÃ© la question de lâ€™utilitÃ© de dÃ©velopper son propre chatbot plutÃ´t que dâ€™utiliser Microsoft Copilot, GitHub Copilot ou ChatGPT. ChatGPT nâ€™Ã©tait pas autorisÃ© pour des raisons de sÃ©curitÃ© : on ne communique pas dâ€™informations internes Ã  lâ€™extÃ©rieur. En revanche, nous avons pu utiliser le moteur GPT-4.1 via les API Azure auxquelles lâ€™entreprise souscrit. Jâ€™ai aussi dÃ©couvert le framework Semantic Kernel de .Net. Deux points ont pu Ãªtre exploitÃ©s : la notion de plugin et celle de RAG, cette derniÃ¨re Ã©tant dâ€™ailleurs accessible via la premiÃ¨re â€” jâ€™y reviendrai dans un autre article. 

*RÃ©sultat trÃ©s gratifiant au final* , mÃªme si j'en conviens, nous n'avons fait qu'utiliser les outils et framework fournis par Microsoft. Par contre, on a quand mÃªme apportÃ©  de notre crÃ©ativitÃ© avec trois fonctionnalitÃ©s qui ont Ã©tÃ© fort bien accueillies et qui, Ã  elles seules, ont justifiÃ© ce developpement: la possibilitÃ©  Ã  l'utilisateur de demander l'ouverture du document source Ã  la bonne page, la possibilitÃ© de noter la qualitÃ© de la rÃ©ponse et la possibilitÃ© au responsable de documentation d'alimenter le RAG via l'interface de l'application en tenant en compte les notes et les commentaires des utilisateurs, ce qui est et restera certainement une activitÃ© humaine! 
